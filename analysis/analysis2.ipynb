{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saketh"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research question/interests\n",
    "\n",
    "Question/Interest: How does the analysis of the dataset allow us to properly understand and invest in stocks without incurring much loss. \n",
    "\n",
    "Why it is important: Once we know how and where to invest properly through analysis, this can help in saving money and protect money especially during inflation and taxes, for example, seeing a stock performing well cosistently that can \n",
    "incline the investors to invest there. Now another way by doing this to almost never incur a loss is if we split our\n",
    "investments into multiple well doing stocks and sectors so you would not be relying on just one with the whole investment.\n",
    "Lastly we also can be aware of where to invest by analsying a company's financial situation by seeing its income flow, and\n",
    "further more which can help us understand their revenue and profitability.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What we are going to do to find the best company to invest in is technically sorting the company based on a specific factor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To do that we are going to calculate the profit per company and compare that with the other companies, which ever has one of the best profits can easily be declared as the one to go for investing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Date       Open       High        Low      Close  Adj Close  \\\n",
      "0        1/2/2013  19.779285  19.821428  19.343929  19.608213  16.862818   \n",
      "1        1/3/2013  19.567142  19.631071  19.321428  19.360714  16.649981   \n",
      "2        1/4/2013  19.177500  19.236786  18.779642  18.821428  16.186199   \n",
      "3        1/7/2013  18.642857  18.903570  18.400000  18.710714  16.090986   \n",
      "4        1/8/2013  18.900356  18.996071  18.616072  18.761070  16.134293   \n",
      "...           ...        ...        ...        ...        ...        ...   \n",
      "73478  12/23/2022  32.240002  32.630001  31.990000  32.119999  32.119999   \n",
      "73479  12/27/2022  31.870001  32.049999  30.980000  31.540001  31.540001   \n",
      "73480  12/28/2022  31.379999  31.530001  30.230000  30.389999  30.389999   \n",
      "73481  12/29/2022  30.799999  31.590000  30.330000  31.100000  31.100000   \n",
      "73482  12/30/2022  30.480000  31.260000  30.260000  31.209999  31.209999   \n",
      "\n",
      "          Volume       Company        Profit  \n",
      "0      560518000         Apple  1.099076e+10  \n",
      "1      352965200         Apple  6.833658e+09  \n",
      "2      594333600         Apple  1.118621e+10  \n",
      "3      484156400         Apple  9.058912e+09  \n",
      "4      458707200         Apple  8.605838e+09  \n",
      "...          ...           ...           ...  \n",
      "73478     277200  Zillow Group  8.903664e+06  \n",
      "73479     516300  Zillow Group  1.628410e+07  \n",
      "73480     588700  Zillow Group  1.789059e+07  \n",
      "73481     532700  Zillow Group  1.656697e+07  \n",
      "73482     698500  Zillow Group  2.180018e+07  \n",
      "\n",
      "[73483 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../data/processed/Merged.csv')\n",
    "\n",
    "list = [[\"Apple\"]*2518, [\"AMD\"]*2518, [\"Amazon\"]*2518, [\"Activision\"]*2518, [\"Ali Baba\"]*2030, [\"Bank of America\"]*2518, [\"Salesforce\"]*2518, [\"Cisco\"]*2518, [\"Disney\"]*2518, [\"EA\"]*2518, [\"Ford\"]*2518, [\"Google\"]*2518, [\"Intel\"]*2518, [\"JP Morgan\"]*2518, [\"CocoCola\"]*2518, [\"McDonalds\"]*2518, [\"Meta\"]*2518, [\"Microsoft\"]*2518, [\"Match\"]*2518, [\"Netflix\"]*2518, [\"Nvidia\"]*2518, [\"Pfizer\"]*2518, [\"Paypal\"]*1887, [\"AT & T\"]*2518,[\"Tesla\"]*2518, [\"Trade Desk\"]*1580, [\"Walmart\"]*2518, [\"Exxon\"]*2518, [\"Yelp\"]*2518, [\"Zillow Group\"]*2518]  # List for company column\n",
    "companies = []\n",
    "\n",
    "for i in list:\n",
    "    for r in i:\n",
    "        companies.append(r)\n",
    "\n",
    "df['Company'] = companies     #this makes a new column for the companies so that it would be easier to clean\n",
    "new = df.groupby('Company') #this groups each company individually\n",
    "df['Profit'] = df['Close'] * df['Volume'] #this calculates profit per company\n",
    "print(df)\n",
    "\n",
    "#UPON cleaning it can be easily said that there are 73482 rows and now 9 comlumns after adding the company and profit columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Company</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61319</th>\n",
       "      <td>12/18/2020</td>\n",
       "      <td>222.966660</td>\n",
       "      <td>231.666672</td>\n",
       "      <td>209.513336</td>\n",
       "      <td>231.666672</td>\n",
       "      <td>231.666672</td>\n",
       "      <td>666378600</td>\n",
       "      <td>Tesla</td>\n",
       "      <td>1.543777e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61537</th>\n",
       "      <td>11/1/2021</td>\n",
       "      <td>381.666656</td>\n",
       "      <td>403.250000</td>\n",
       "      <td>372.886658</td>\n",
       "      <td>402.863342</td>\n",
       "      <td>402.863342</td>\n",
       "      <td>168146100</td>\n",
       "      <td>Tesla</td>\n",
       "      <td>6.773990e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61332</th>\n",
       "      <td>1/8/2021</td>\n",
       "      <td>285.333344</td>\n",
       "      <td>294.829987</td>\n",
       "      <td>279.463318</td>\n",
       "      <td>293.339996</td>\n",
       "      <td>293.339996</td>\n",
       "      <td>225166500</td>\n",
       "      <td>Tesla</td>\n",
       "      <td>6.605034e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61532</th>\n",
       "      <td>10/25/2021</td>\n",
       "      <td>316.843323</td>\n",
       "      <td>348.339996</td>\n",
       "      <td>314.733337</td>\n",
       "      <td>341.619995</td>\n",
       "      <td>341.619995</td>\n",
       "      <td>188556300</td>\n",
       "      <td>Tesla</td>\n",
       "      <td>6.441460e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61533</th>\n",
       "      <td>10/26/2021</td>\n",
       "      <td>341.563324</td>\n",
       "      <td>364.980011</td>\n",
       "      <td>333.813324</td>\n",
       "      <td>339.476654</td>\n",
       "      <td>339.476654</td>\n",
       "      <td>187245000</td>\n",
       "      <td>Tesla</td>\n",
       "      <td>6.356531e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date        Open        High         Low       Close   Adj Close  \\\n",
       "61319  12/18/2020  222.966660  231.666672  209.513336  231.666672  231.666672   \n",
       "61537   11/1/2021  381.666656  403.250000  372.886658  402.863342  402.863342   \n",
       "61332    1/8/2021  285.333344  294.829987  279.463318  293.339996  293.339996   \n",
       "61532  10/25/2021  316.843323  348.339996  314.733337  341.619995  341.619995   \n",
       "61533  10/26/2021  341.563324  364.980011  333.813324  339.476654  339.476654   \n",
       "\n",
       "          Volume Company        Profit  \n",
       "61319  666378600   Tesla  1.543777e+11  \n",
       "61537  168146100   Tesla  6.773990e+10  \n",
       "61332  225166500   Tesla  6.605034e+10  \n",
       "61532  188556300   Tesla  6.441460e+10  \n",
       "61533  187245000   Tesla  6.356531e+10  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hprofit = df.sort_values(by=['Profit'],ascending = False) # This sorts the list of companies based on their profits\n",
    "hprofit.head(5)   # this step helps us see the top 5 companies with the highest profit\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As we can see that Tesla is the company with the highest profit of all so personally I would invest there"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6773b4cfd51867c23bf57b338111b20f8833119214edace8f00207c37a789176"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
